{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<a href=\"https://github.com/groda/big_data\"><div><img src=\"https://github.com/groda/big_data/blob/master/logo_bdb.png?raw=true\" align=right width=\"90\" alt=\"Logo Big Data for Beginners\"></div></a>\n",
        "# Apache Sedona with PySpark\n",
        "\n",
        "Apache Sedona™ is\n",
        "\n",
        "> *a cluster computing system for processing large-scale spatial data. Sedona extends existing cluster computing systems, such as Apache Spark, Apache Flink, and Snowflake, with a set of out-of-the-box distributed Spatial Datasets and Spatial SQL that efficiently load, process, and analyze large-scale spatial data across machines.* ([https://sedona.apache.org/](https://sedona.apache.org/))\n",
        "\n",
        "To execute a basic Sedona demonstration using PySpark on Google Colab, we made a few minor adjustments. The Sedona notebook starts below at [Apache Sedona Core demo](#scrollTo=Apache_Sedona_Core_demo).\n",
        "\n"
      ],
      "metadata": {
        "id": "DNWKwG4TAcD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Apache Sedona and PySpark\n",
        "\n",
        "To start with, we are going to install PySpark with Sedona following the instructions at: https://sedona.apache.org/latest-snapshot/setup/install-python/ but first we need to downgrade `shapely` because the version 2.0.2 that comes with Google Colab does not play well with the current version of Apache Sedona (see https://shapely.readthedocs.io/en/stable/migration.html)."
      ],
      "metadata": {
        "id": "3AQNoWmX_B78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downgrade Shapely to version 1.7.1\n",
        "\n",
        "We need to install install any version of `shapely>=1.7.0` but smaller than `2.0`. We picked `1.7.1` because with 1.7.0 we got the error\n",
        "\n",
        "    geopandas 0.13.2 requires shapely>=1.7.1, but you have shapely 1.7.0 which is incompatible.\n",
        "\n",
        "Explanation for `pip -I`:\n",
        "\n",
        "- [`-I, --ignore-installed`](https://pip.pypa.io/en/stable/cli/pip_install/#cmdoption-I)\n",
        "> Ignore the installed packages, overwriting them. This can break your system if the existing package is of a different version or was installed with a different package manager!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zDoBDC3yAVvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -I shapely==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4nnDMo0Blfu",
        "outputId": "b910f95f-488d-4080-b174-af18c017ffbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shapely==1.7.1\n",
            "  Downloading Shapely-1.7.1.tar.gz (383 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: shapely\n",
            "  Building wheel for shapely (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shapely: filename=Shapely-1.7.1-cp310-cp310-linux_x86_64.whl size=997457 sha256=12409674af69c78130a1814d8833c2048aeba23af5c6daa847852d6726f107b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/fa/97/c85f587c35afcaf4a81c481741d36592518d1e50445572f0d4\n",
            "Successfully built shapely\n",
            "Installing collected packages: shapely\n",
            "Successfully installed shapely-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Geopandas\n",
        "\n",
        "This step is only needed outside of Colab because on Google Colab `geopandas` is available by default."
      ],
      "metadata": {
        "id": "76yI9hGZz_Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas==0.13.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KliMM6ka0Qee",
        "outputId": "e8eae0e1-9530-4672-f2df-e6cc07879ebe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas==0.13.2 in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (1.9.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (24.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (2.0.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (1.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (2024.2.2)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas==0.13.2) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas==0.13.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas==0.13.2) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas==0.13.2) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas==0.13.2) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Apache Sedona and PySpark\n",
        "\n",
        "We can now install Apache Sedona together with PySpark (and Spark)."
      ],
      "metadata": {
        "id": "Vv5bhPBIDQ5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOB7DNZ6AOio",
        "outputId": "da035da9-b335-4596-d3d6-ff15c22ff097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-sedona[spark]\n",
            "  Downloading apache_sedona-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-sedona[spark]) (23.2.0)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-sedona[spark]) (1.7.1)\n",
            "Collecting pyspark>=2.3.0 (from apache-sedona[spark])\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark>=2.3.0->apache-sedona[spark]) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=cbcdc0ee7eca515787f0b7437f11b2dcbcef714553606759a1a1fceda39e0483\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark, apache-sedona\n",
            "Successfully installed apache-sedona-1.5.1 pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-sedona[spark]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env SPARK_HOME = \"/usr/local/lib/python3.10/dist-packages/pyspark\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoNNqcGaGrEh",
        "outputId": "6d7016c5-23a2-4d49-c298-d5759dd96603"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SPARK_HOME=\"/usr/local/lib/python3.10/dist-packages/pyspark\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH = /usr/local/lib/python3.10/dist-packages/pyspark/python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9fpbLrjHBeY",
        "outputId": "8f1a3074-315b-490d-c3e3-56adc09818ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=/usr/local/lib/python3.10/dist-packages/pyspark/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip info pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_YNI8fKiU3k",
        "outputId": "5b3bf545-3bf9-478e-e554-f4d18a2c6a92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"info\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment variables\n",
        "\n",
        "We need to set two environment variables:\n",
        "\n",
        "- `SPARK_HOME`\n",
        "- `PYTHONPATH`\n",
        "\n",
        "Once we have set `SPARK_HOME`, the variable `PYTHONPATH` is `$SPARK_HOME/python`.\n",
        "\n",
        "### Find Spark home\n",
        "\n",
        "There's an utility to find Spark home and I always forget how it's called exactly, what I remember is that it contains `\"find\"` and `\"spark\"`. Let us search for it:"
      ],
      "metadata": {
        "id": "Sjlr4JO-Erv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name \"*find*spark*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK5vO9MUGQA6",
        "outputId": "5ba8686c-48ae-469f-8903-6fd744954aa2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/62/task/62/net’: Invalid argument\n",
            "find: ‘/proc/62/net’: Invalid argument\n",
            "find: ‘/proc/811’: No such file or directory\n",
            "/usr/local/bin/find_spark_home.py\n",
            "/usr/local/bin/find-spark-home\n",
            "/usr/local/bin/__pycache__/find_spark_home.cpython-310.pyc\n",
            "/usr/local/bin/find-spark-home.cmd\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/bin/find-spark-home\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/bin/find-spark-home.cmd\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/find_spark_home.py\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/__pycache__/find_spark_home.cpython-310.pyc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script `/usr/local/bin/find_spark_home.py` is successful at finding Spark's home."
      ],
      "metadata": {
        "id": "Nr_2rb6pFzF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set `SPARK_HOME`"
      ],
      "metadata": {
        "id": "qxlEqcY9LRI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "  output = !python /usr/local/bin/find_spark_home.py\n",
        "else:\n",
        "  output = !find / -name \"pyspark\" -type d 2>/dev/null|head -1\n",
        "# Store the output using %store\n",
        "%store output\n",
        "# get rid of extra quotation marks\n",
        "os.environ['SPARK_HOME'] = output[0].replace('\"', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCgU9MnaIZ_k",
        "outputId": "698952a9-ef54-46b5-d72a-8ce48a19fa3e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'output' (SList)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olIKq1bOkMDy",
        "outputId": "d78486ac-d885-446d-da9b-12bff202c3c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyspark\n",
            "Version: 3.5.1\n",
            "Summary: Apache Spark Python API\n",
            "Home-page: https://github.com/apache/spark/tree/master/python\n",
            "Author: Spark Developers\n",
            "Author-email: dev@spark.apache.org\n",
            "License: http://www.apache.org/licenses/LICENSE-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: py4j\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the correct `SPARK_HOME` has been set."
      ],
      "metadata": {
        "id": "Ic1uHIKAK1ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['SPARK_HOME']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BraJPa5KZY1y",
        "outputId": "7e81261b-63a9-485f-ace1-8530590311b5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env SPARK_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sONAYA_DKOry",
        "outputId": "865501f6-184a-4913-8c76-c2e8262d22ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set `PYTHONPATH`"
      ],
      "metadata": {
        "id": "gQ3zuxd9LKxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTHONPATH'] = os.environ['SPARK_HOME'] + '/python'"
      ],
      "metadata": {
        "id": "SOXsRzqNLAqx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check"
      ],
      "metadata": {
        "id": "HTzSh-RBLbsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Log-_SFWJScq",
        "outputId": "58b251d6-9f33-4252-d619-0265b99cbdb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/pyspark/python'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data\n",
        "\n",
        "In order to run, the Sedona notebook expects to find some specific files in the local folder `data`. Let us populate `data` with the files from the Sedona Github repository."
      ],
      "metadata": {
        "id": "qi3MxEWpV9CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# it would be more efficient to just download the \"data\" folder and not the whole repo\n",
        "![ -d sedona ] || git clone https://github.com/apache/sedona.git\n",
        "\n",
        "!cp -r sedona/binder/data ./"
      ],
      "metadata": {
        "id": "wnzi7JCOIA1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f69dc0-dee1-4058-e0d5-4bd2ef66aa73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sedona'...\n",
            "remote: Enumerating objects: 77039, done.\u001b[K\n",
            "remote: Counting objects: 100% (77039/77039), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15583/15583), done.\u001b[K\n",
            "remote: Total 77039 (delta 49225), reused 76480 (delta 48959), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (77039/77039), 588.20 MiB | 24.26 MiB/s, done.\n",
            "Resolving deltas: 100% (49225/49225), done.\n",
            "Updating files: 100% (1243/1243), done.\n",
            "cp: cannot stat 'sedona/binder/data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the presence of data in the designated `data` folder."
      ],
      "metadata": {
        "id": "qQVz6ckaScn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxy-t1JnRnf6",
        "outputId": "5d496b17-69c3-4662-d984-c0f1edc8084a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apache Sedona Core demo\n",
        "\n",
        "The notebook is available at the following link:\n",
        "https://github.com/apache/sedona/blob/master/binder/ApacheSedonaCore.ipynb\n"
      ],
      "metadata": {
        "id": "Mk20FV3ZHj_U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcjGVcGzOjcK"
      },
      "source": [
        "```\n",
        "Licensed to the Apache Software Foundation (ASF) under one\n",
        "or more contributor license agreements.  See the NOTICE file\n",
        "distributed with this work for additional information\n",
        "regarding copyright ownership.  The ASF licenses this file\n",
        "to you under the Apache License, Version 2.0 (the\n",
        "\"License\"); you may not use this file except in compliance\n",
        "with the License.  You may obtain a copy of the License at\n",
        "  http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing,\n",
        "software distributed under the License is distributed on an\n",
        "\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "KIND, either express or implied.  See the License for the\n",
        "specific language governing permissions and limitations\n",
        "under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sK9oIz0FOjcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c22e82-9e31-4044-b9be-6a692519d431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping SedonaKepler import, verify if keplergl is installed\n",
            "Skipping SedonaPyDeck import, verify if pydeck is installed\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import StorageLevel\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from pyspark.sql.types import StructType\n",
        "from pyspark.sql.types import StructField\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.types import LongType\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "from sedona.spark import *\n",
        "from sedona.core.geom.envelope import Envelope\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HzVqFLBtOjcO"
      },
      "outputs": [],
      "source": [
        "config = SedonaContext.builder() .\\\n",
        "    config('spark.jars.packages',\n",
        "           'org.apache.sedona:sedona-spark-3.4_2.12:1.5.1,'\n",
        "           'org.datasyslab:geotools-wrapper:1.5.1-28.2,'\n",
        "           'uk.co.gresearch.spark:spark-extension_2.12:2.11.0-3.4'). \\\n",
        "    config('spark.jars.repositories', 'https://artifacts.unidata.ucar.edu/repository/unidata-all'). \\\n",
        "    getOrCreate()\n",
        "\n",
        "sedona = SedonaContext.create(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JI32GOnEOjcO"
      },
      "outputs": [],
      "source": [
        "sc = sedona.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdQM3oaYOjcO"
      },
      "source": [
        "# Create SpatialRDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2umXxYfOjcO"
      },
      "source": [
        "## Reading to PointRDD from CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Rgv--0OjcP"
      },
      "source": [
        "Suppose we want load the CSV file into Apache Sedona PointRDD\n",
        "```\n",
        "testattribute0,-88.331492,32.324142,testattribute1,testattribute2\n",
        "testattribute0,-88.175933,32.360763,testattribute1,testattribute2\n",
        "testattribute0,-88.388954,32.357073,testattribute1,testattribute2\n",
        "testattribute0,-88.221102,32.35078,testattribute1,testattribute2\n",
        "testattribute0,-88.323995,32.950671,testattribute1,testattribute2\n",
        "testattribute0,-88.231077,32.700812,testattribute1,testattribute2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gusbYu1fOjcP"
      },
      "outputs": [],
      "source": [
        "point_rdd = PointRDD(sc, \"data/arealm-small.csv\", 1, FileDataSplitter.CSV, True, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykc5FwouOjcP"
      },
      "outputs": [],
      "source": [
        "## Getting approximate total count\n",
        "point_rdd.approximateTotalCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdEjrrRHOjcP"
      },
      "outputs": [],
      "source": [
        "# getting boundary for PointRDD or any other SpatialRDD, it returns Enelope object which inherits from\n",
        "# shapely.geometry.Polygon\n",
        "point_rdd.boundary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDV2-f2tOjcP"
      },
      "outputs": [],
      "source": [
        "# To run analyze please use function analyze\n",
        "point_rdd.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puMA8o6POjcP"
      },
      "outputs": [],
      "source": [
        "# Finding boundary envelope for PointRDD or any other SpatialRDD, it returns Enelope object which inherits from\n",
        "# shapely.geometry.Polygon\n",
        "point_rdd.boundaryEnvelope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgOCi8lJOjcQ"
      },
      "outputs": [],
      "source": [
        "# Calculate number of records without duplicates\n",
        "point_rdd.countWithoutDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-l1BvhakOjcQ"
      },
      "outputs": [],
      "source": [
        "# Getting source epsg code\n",
        "point_rdd.getSourceEpsgCode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiFEDeNdOjcQ"
      },
      "outputs": [],
      "source": [
        "# Getting target epsg code\n",
        "point_rdd.getTargetEpsgCode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oip1bNogOjcQ"
      },
      "outputs": [],
      "source": [
        "# Spatial partitioning data\n",
        "point_rdd.spatialPartitioning(GridType.KDBTREE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setaW5adOjcQ"
      },
      "source": [
        "## Operations on RawSpatialRDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeAQe3qqOjcQ"
      },
      "source": [
        "rawSpatialRDD method returns RDD which consists of GeoData objects which has 2 attributes\n",
        "<li> geom: shapely.geometry.BaseGeometry </li>\n",
        "<li> userData: str </li>\n",
        "\n",
        "You can use any operations on those objects and spread across machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNlkO6kYOjcR"
      },
      "outputs": [],
      "source": [
        "# take firs element\n",
        "point_rdd.rawSpatialRDD.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22UNTZiIOjcR"
      },
      "outputs": [],
      "source": [
        "# collect to Python list\n",
        "point_rdd.rawSpatialRDD.collect()[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vz8jzj6OjcR"
      },
      "outputs": [],
      "source": [
        "# apply map functions, for example distance to Point(52 21)\n",
        "point_rdd.rawSpatialRDD.map(lambda x: x.geom.distance(Point(21, 52))).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJUwfnWbOjcR"
      },
      "source": [
        "## Transforming to GeoPandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJT4cqunOjcR"
      },
      "source": [
        "## Loaded data can be transformed to GeoPandas DataFrame in a few ways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENst5TKKOjcR"
      },
      "source": [
        "### Directly from RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khvSdVtROjcR"
      },
      "outputs": [],
      "source": [
        "point_rdd_to_geo = point_rdd.rawSpatialRDD.map(lambda x: [x.geom, *x.getUserData().split(\"\\t\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_aQLibwOjcR"
      },
      "outputs": [],
      "source": [
        "point_gdf = gpd.GeoDataFrame(\n",
        "    point_rdd_to_geo.collect(), columns=[\"geom\", \"attr1\", \"attr2\", \"attr3\"], geometry=\"geom\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht7qYNuwOjcS"
      },
      "outputs": [],
      "source": [
        "point_gdf[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vW97p_iOjcS"
      },
      "source": [
        "### Using Adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HN0IIhZ8OjcS"
      },
      "outputs": [],
      "source": [
        "# Adapter allows you to convert geospatial data types introduced with sedona to other ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69dR65hgOjcS"
      },
      "outputs": [],
      "source": [
        "spatial_df = Adapter.\\\n",
        "    toDf(point_rdd, [\"attr1\", \"attr2\", \"attr3\"], sedona).\\\n",
        "    createOrReplaceTempView(\"spatial_df\")\n",
        "\n",
        "spatial_gdf = sedona.sql(\"Select attr1, attr2, attr3, geometry as geom from spatial_df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnGQMPUIOjcS"
      },
      "outputs": [],
      "source": [
        "spatial_gdf.show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdL0awafOjcS"
      },
      "outputs": [],
      "source": [
        "gpd.GeoDataFrame(spatial_gdf.toPandas(), geometry=\"geom\")[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilmR8RjIOjcS"
      },
      "source": [
        "### With DataFrame creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqgFLBZEOjcT"
      },
      "outputs": [],
      "source": [
        "schema = StructType(\n",
        "    [\n",
        "        StructField(\"geometry\", GeometryType(), False),\n",
        "        StructField(\"attr1\", StringType(), False),\n",
        "        StructField(\"attr2\", StringType(), False),\n",
        "        StructField(\"attr3\", StringType(), False),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEO42a4DOjcT"
      },
      "outputs": [],
      "source": [
        "geo_df = sedona.createDataFrame(point_rdd_to_geo, schema, verifySchema=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaIAqir1OjcT"
      },
      "outputs": [],
      "source": [
        "gpd.GeoDataFrame(geo_df.toPandas(), geometry=\"geometry\")[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO1EyFACOjcT"
      },
      "source": [
        "# Load Typed SpatialRDDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_0_hHNQOjcT"
      },
      "source": [
        "Currently The library supports 5 typed SpatialRDDs:\n",
        "<li> RectangleRDD </li>\n",
        "<li> PointRDD </li>\n",
        "<li> PolygonRDD </li>\n",
        "<li> LineStringRDD </li>\n",
        "<li> CircleRDD </li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m2k-n-LOjcT"
      },
      "outputs": [],
      "source": [
        "rectangle_rdd = RectangleRDD(sc, \"data/zcta510-small.csv\", FileDataSplitter.CSV, True, 11)\n",
        "point_rdd = PointRDD(sc, \"data/arealm-small.csv\", 1, FileDataSplitter.CSV, False, 11)\n",
        "polygon_rdd = PolygonRDD(sc, \"data/primaryroads-polygon.csv\", FileDataSplitter.CSV, True, 11)\n",
        "linestring_rdd = LineStringRDD(sc, \"data/primaryroads-linestring.csv\", FileDataSplitter.CSV, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRHPdLYdOjcb"
      },
      "outputs": [],
      "source": [
        "rectangle_rdd.analyze()\n",
        "point_rdd.analyze()\n",
        "polygon_rdd.analyze()\n",
        "linestring_rdd.analyze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2uTMMk1Ojcb"
      },
      "source": [
        "# Spatial Partitioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3AC5CpdOjcc"
      },
      "source": [
        "Apache Sedona spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2icbQf9NOjcc"
      },
      "outputs": [],
      "source": [
        "point_rdd.spatialPartitioning(GridType.KDBTREE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ipdd7umOjcc"
      },
      "source": [
        "# Create Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEPaVPmJOjcc"
      },
      "source": [
        "Apache Sedona provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, Apache Sedona will build a local tree index on each of the SpatialRDD partition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YIsx_55Ojcc"
      },
      "outputs": [],
      "source": [
        "point_rdd.buildIndex(IndexType.RTREE, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRHcULQDOjcc"
      },
      "source": [
        "# SpatialJoin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnnDo119Ojcc"
      },
      "source": [
        "Spatial join is operation which combines data based on spatial relations like:\n",
        "<li> intersects </li>\n",
        "<li> touches </li>\n",
        "<li> within </li>\n",
        "<li> etc </li>\n",
        "\n",
        "To Use Spatial Join in GeoPyspark library please use JoinQuery object, which has implemented below methods:\n",
        "```python\n",
        "SpatialJoinQuery(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
        "\n",
        "DistanceJoinQuery(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
        "\n",
        "spatialJoin(queryWindowRDD: SpatialRDD, objectRDD: SpatialRDD, joinParams: JoinParams) -> RDD\n",
        "\n",
        "DistanceJoinQueryFlat(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
        "\n",
        "SpatialJoinQueryFlat(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icOL3ukTOjcc"
      },
      "source": [
        "## Example SpatialJoinQueryFlat PointRDD with RectangleRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unG1rYNZOjcc"
      },
      "outputs": [],
      "source": [
        "# partitioning the data\n",
        "point_rdd.spatialPartitioning(GridType.KDBTREE)\n",
        "rectangle_rdd.spatialPartitioning(point_rdd.getPartitioner())\n",
        "# building an index\n",
        "point_rdd.buildIndex(IndexType.RTREE, True)\n",
        "# Perform Spatial Join Query\n",
        "result = JoinQuery.SpatialJoinQueryFlat(point_rdd, rectangle_rdd, False, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A0s6CE5Ojcd"
      },
      "source": [
        "As result we will get RDD[GeoData, GeoData]\n",
        "It can be used like any other Python RDD. You can use map, take, collect and other functions  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dw_JRafOjcd"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QKdzz9ZOjcd"
      },
      "outputs": [],
      "source": [
        "result.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBMsFNe2Ojcd"
      },
      "outputs": [],
      "source": [
        "result.collect()[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUPAfZ0wOjcd"
      },
      "outputs": [],
      "source": [
        "# getting distance using SpatialObjects\n",
        "result.map(lambda x: x[0].geom.distance(x[1].geom)).take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ztnCLMnOjcd"
      },
      "outputs": [],
      "source": [
        "# getting area of polygon data\n",
        "result.map(lambda x: x[0].geom.area).take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt-r8k9VOjcd"
      },
      "outputs": [],
      "source": [
        "# Base on result you can create DataFrame object, using map function and build DataFrame from RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nALxyjQiOjce"
      },
      "outputs": [],
      "source": [
        "schema = StructType(\n",
        "    [\n",
        "        StructField(\"geom_left\", GeometryType(), False),\n",
        "        StructField(\"geom_right\", GeometryType(), False)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWqys-lqOjce"
      },
      "outputs": [],
      "source": [
        "# Set verifySchema to False\n",
        "spatial_join_result = result.map(lambda x: [x[0].geom, x[1].geom])\n",
        "sedona.createDataFrame(spatial_join_result, schema, verifySchema=False).show(5, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkY70z0lOjce"
      },
      "outputs": [],
      "source": [
        "# Above code produces DataFrame with geometry Data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BQVrY-IOjce"
      },
      "outputs": [],
      "source": [
        "sedona.createDataFrame(spatial_join_result, schema, verifySchema=False).printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oID6P5kOjce"
      },
      "source": [
        "We can create DataFrame object from Spatial Pair RDD using Adapter object as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyD3_m_zOjce"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(result, [\"attr1\"], [\"attr2\"], sedona).show(5, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAmXD2SKOjce"
      },
      "source": [
        "This also produce DataFrame with geometry DataType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7evFgqkOjce"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(result, [\"attr1\"], [\"attr2\"], sedona).printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TldNHgcQOjcf"
      },
      "source": [
        "We can create RDD which will be of type RDD[GeoData, List[GeoData]]\n",
        "We can for example calculate number of Points within some polygon data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlhD3mSvOjcf"
      },
      "source": [
        "To do that we can use code specified below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl5mg9qdOjcf"
      },
      "outputs": [],
      "source": [
        "point_rdd.spatialPartitioning(GridType.KDBTREE)\n",
        "rectangle_rdd.spatialPartitioning(point_rdd.getPartitioner())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S1gs7nDOjcf"
      },
      "outputs": [],
      "source": [
        "spatial_join_result_non_flat = JoinQuery.SpatialJoinQuery(point_rdd, rectangle_rdd, False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJiTacNkOjcf"
      },
      "outputs": [],
      "source": [
        "# number of point for each polygon\n",
        "number_of_points = spatial_join_result_non_flat.map(lambda x: [x[0].geom, x[1].__len__()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EtrJVuROjcf"
      },
      "outputs": [],
      "source": [
        "schema = StructType([\n",
        "    StructField(\"geometry\", GeometryType(), False),\n",
        "    StructField(\"number_of_points\", LongType(), False)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mktoa5-HOjcf"
      },
      "outputs": [],
      "source": [
        "sedona.createDataFrame(number_of_points, schema, verifySchema=False).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZosmctfPOjcf"
      },
      "source": [
        "# KNNQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utC2fQXwOjcg"
      },
      "source": [
        "Spatial KNNQuery is operation which help us find answer which k number of geometries lays closest to other geometry.\n",
        "\n",
        "For Example:\n",
        "    5 closest Shops to your home. To use Spatial KNNQuery please use object\n",
        "<b> KNNQuery </b> which has one method:\n",
        "```python\n",
        "SpatialKnnQuery(spatialRDD: SpatialRDD, originalQueryPoint: BaseGeometry, k: int,  useIndex: bool)-> List[GeoData]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTcvQarvOjcg"
      },
      "source": [
        "### Finds 5 closest points from PointRDD to given Point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6BIfKk9Ojcg"
      },
      "outputs": [],
      "source": [
        "result = KNNQuery.SpatialKnnQuery(point_rdd, Point(-84.01, 34.01), 5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-SgOWD2Ojcg"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dft5_7AMOjcg"
      },
      "source": [
        "As Reference geometry you can also use Polygon or LineString object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-G_a1iXOjcg"
      },
      "outputs": [],
      "source": [
        "polygon = Polygon(\n",
        "    [(-84.237756, 33.904859), (-84.237756, 34.090426),\n",
        "     (-83.833011, 34.090426), (-83.833011, 33.904859),\n",
        "     (-84.237756, 33.904859)\n",
        "    ])\n",
        "polygons_nearby = KNNQuery.SpatialKnnQuery(polygon_rdd, polygon, 5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYtK1T1oOjcg"
      },
      "outputs": [],
      "source": [
        "polygons_nearby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4Mf5TP-Ojcg"
      },
      "outputs": [],
      "source": [
        "polygons_nearby[0].geom.wkt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxP3ufPGOjch"
      },
      "source": [
        "# RangeQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Air8I_XIOjch"
      },
      "source": [
        "A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that intersect / are fully covered by the query window.\n",
        "RangeQuery has one method:\n",
        "\n",
        "```python\n",
        "SpatialRangeQuery(self, spatialRDD: SpatialRDD, rangeQueryWindow: BaseGeometry, considerBoundaryIntersection: bool, usingIndex: bool) -> RDD\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YQd4wvuOjch"
      },
      "outputs": [],
      "source": [
        "from sedona.core.geom.envelope import Envelope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WLf9PLbOjch"
      },
      "outputs": [],
      "source": [
        "query_envelope = Envelope(-85.01, -60.01, 34.01, 50.01)\n",
        "\n",
        "result_range_query = RangeQuery.SpatialRangeQuery(linestring_rdd, query_envelope, False, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Wp7sOciOjch"
      },
      "outputs": [],
      "source": [
        "result_range_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1mittdHOjch"
      },
      "outputs": [],
      "source": [
        "result_range_query.take(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv3ik2obOjch"
      },
      "outputs": [],
      "source": [
        "# Creating DataFrame from result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF2xJfLCOjch"
      },
      "outputs": [],
      "source": [
        "schema = StructType([StructField(\"geometry\", GeometryType(), False)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y4ruCQ-Ojci"
      },
      "outputs": [],
      "source": [
        "sedona.createDataFrame(\n",
        "    result_range_query.map(lambda x: [x.geom]),\n",
        "    schema,\n",
        "    verifySchema=False\n",
        ").show(5, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwiSJcuLOjci"
      },
      "source": [
        "# Load From other Formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLuQLIfJOjci"
      },
      "source": [
        "GeoPyspark allows to load the data from other Data formats like:\n",
        "<li> GeoJSON </li>\n",
        "<li> Shapefile </li>\n",
        "<li> WKB </li>\n",
        "<li> WKT </li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuiEDP9uOjci"
      },
      "outputs": [],
      "source": [
        "## ShapeFile - load to SpatialRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bcx_gxAOjci"
      },
      "outputs": [],
      "source": [
        "shape_rdd = ShapefileReader.readToGeometryRDD(sc, \"data/polygon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIjo83o8Ojci"
      },
      "outputs": [],
      "source": [
        "shape_rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y9EXCKfOjci"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(shape_rdd, sedona).show(5, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkVpdZgGOjci"
      },
      "outputs": [],
      "source": [
        "## GeoJSON - load to SpatialRDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh1K7181Ojcj"
      },
      "source": [
        "```\n",
        "{ \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"077\", \"TRACTCE\": \"011501\", \"BLKGRPCE\": \"5\", \"AFFGEOID\": \"1500000US010770115015\", \"GEOID\": \"010770115015\", \"NAME\": \"5\", \"LSAD\": \"BG\", \"ALAND\": 6844991, \"AWATER\": 32636 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -87.621765, 34.873444 ], [ -87.617535, 34.873369 ], [ -87.6123, 34.873337 ], [ -87.604049, 34.873303 ], [ -87.604033, 34.872316 ], [ -87.60415, 34.867502 ], [ -87.604218, 34.865687 ], [ -87.604409, 34.858537 ], [ -87.604018, 34.851336 ], [ -87.603716, 34.844829 ], [ -87.603696, 34.844307 ], [ -87.603673, 34.841884 ], [ -87.60372, 34.841003 ], [ -87.603879, 34.838423 ], [ -87.603888, 34.837682 ], [ -87.603889, 34.83763 ], [ -87.613127, 34.833938 ], [ -87.616451, 34.832699 ], [ -87.621041, 34.831431 ], [ -87.621056, 34.831526 ], [ -87.62112, 34.831925 ], [ -87.621603, 34.8352 ], [ -87.62158, 34.836087 ], [ -87.621383, 34.84329 ], [ -87.621359, 34.844438 ], [ -87.62129, 34.846387 ], [ -87.62119, 34.85053 ], [ -87.62144, 34.865379 ], [ -87.621765, 34.873444 ] ] ] } },\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_a3q71ZOjcj"
      },
      "outputs": [],
      "source": [
        "geo_json_rdd = GeoJsonReader.readToGeometryRDD(sc, \"data/testPolygon.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGrMegQ6Ojcj"
      },
      "outputs": [],
      "source": [
        "geo_json_rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfH32XssOjcj"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(geo_json_rdd, sedona).drop(\"AWATER\").show(5, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuJkRwbROjcj"
      },
      "outputs": [],
      "source": [
        "## WKT - loading to SpatialRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d9owuZROjcj"
      },
      "outputs": [],
      "source": [
        "wkt_rdd = WktReader.readToGeometryRDD(sc, \"data/county_small.tsv\", 0, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKALKBbeOjcj"
      },
      "outputs": [],
      "source": [
        "wkt_rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUJfqy5EOjcj"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(wkt_rdd, sedona).printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjIgGZB2Ojck"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(wkt_rdd, sedona).show(5, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CzKWF_ZOjck"
      },
      "outputs": [],
      "source": [
        "## WKB - load to SpatialRDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-saFLNoOjck"
      },
      "outputs": [],
      "source": [
        "wkb_rdd = WkbReader.readToGeometryRDD(sc, \"data/county_small_wkb.tsv\", 0, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFUhy3AtOjck"
      },
      "outputs": [],
      "source": [
        "Adapter.toDf(wkb_rdd, sedona).show(5, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj-mt-60Ojck"
      },
      "source": [
        "## Converting RDD Spatial join result to DF directly, avoiding jvm python serde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DTG6EvFOjck"
      },
      "outputs": [],
      "source": [
        "point_rdd.spatialPartitioning(GridType.KDBTREE)\n",
        "rectangle_rdd.spatialPartitioning(point_rdd.getPartitioner())\n",
        "# building an index\n",
        "point_rdd.buildIndex(IndexType.RTREE, True)\n",
        "# Perform Spatial Join Query\n",
        "result = JoinQueryRaw.SpatialJoinQueryFlat(point_rdd, rectangle_rdd, False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs8XaQ6kOjck"
      },
      "outputs": [],
      "source": [
        "# without passing column names, the result will contain only two geometries columns\n",
        "geometry_df = Adapter.toDf(result, sedona)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiWJjHz7Ojck"
      },
      "outputs": [],
      "source": [
        "geometry_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUuhG1HHOjcl"
      },
      "outputs": [],
      "source": [
        "geometry_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_113xc7Ojcl"
      },
      "outputs": [],
      "source": [
        "geometry_df.collect()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-eRk6AROjcl"
      },
      "source": [
        "## Passing column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CnT4RzeOjcl"
      },
      "outputs": [],
      "source": [
        "geometry_df = Adapter.toDf(result, [\"left_user_data\"], [\"right_user_data\"], sedona)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfaNUcXQOjcl"
      },
      "outputs": [],
      "source": [
        "geometry_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzWjjT0UOjcl"
      },
      "source": [
        "# Converting RDD Spatial join result to DF directly, avoiding jvm python serde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB_t5UOcOjcl"
      },
      "outputs": [],
      "source": [
        "query_envelope = Envelope(-85.01, -60.01, 34.01, 50.01)\n",
        "\n",
        "result_range_query = RangeQueryRaw.SpatialRangeQuery(linestring_rdd, query_envelope, False, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58B9hoX_Ojcl"
      },
      "outputs": [],
      "source": [
        "# converting to df\n",
        "gdf = Adapter.toDf(result_range_query, sedona)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgna3MsmOjcl"
      },
      "outputs": [],
      "source": [
        "gdf.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzw-LrkgOjcm"
      },
      "outputs": [],
      "source": [
        "gdf.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5-BtLhSOjcm"
      },
      "outputs": [],
      "source": [
        "# Passing column names\n",
        "# converting to df\n",
        "gdf_with_columns = Adapter.toDf(result_range_query, sedona, [\"_c1\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9ctqnn1Ojcm"
      },
      "outputs": [],
      "source": [
        "gdf_with_columns.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-xj5agIOjcm"
      },
      "outputs": [],
      "source": [
        "gdf_with_columns.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "We have shown how to install Sedona with Pyspark and run a basic example (source: https://github.com/apache/sedona/blob/master/binder/ApacheSedonaCore.ipynb) on Google Colab."
      ],
      "metadata": {
        "id": "VIQE0WpbUQjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"22022503 Nguen Nhat Minh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsszQqOHaWH_",
        "outputId": "39f71d20-9efb-4e0c-f9e3-8fb6310b2a49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22022503 Nguen Nhat Minh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giQM80Dfc95A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}